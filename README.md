---
license: openrail++
tags:
- text-to-image
- stable-diffusion
- logos
---

---

<div align="center"><h1 align="center">~ Chhavi ~</h1><img src="https://huggingface.co/budecosystem/Chhavi/resolve/main/cool.png" alt="Vector anime chibi style logo featuring a single piece of flaming piece of popcorn with a smiling face, with mirrorshades sunglasses, popcorn as morpheus, clean composition, symmetrical" width=150 style="border-radius: 150px;"></div>


<p align="center"><i>Democratizing access to generative-ai-models for the open-source community.<br>Let's advance AI, together. </i></p>

---

## Capability ~~Showcase~~ Show-off (a.k.a patti show) üòé

![results](https://huggingface.co/budecosystem/Chhavi/resolve/main/demo.png)

---

<h2> Introduction üéâ </h2>

Welcome to **Chhavi**, a Latent Diffusion Model (LDM) fine-tuned on the foundation of StablitiyAI's open-source SDXL model. At Bud Ecosystem, we believe in the power of open-source collaboration to drive the advancement of technology at an accelerated pace. Our vision is to democratize access to fine-tuned generative-ai-models (LLMs, LDMs etc...), and to that end, we will be releasing a series of models for the open-source community to use, enhance, and build upon.

Chhavi is finetuned on a subset of our internal dataset and is first in the release cycle of our finetune series of Diffusion Models. The model still has room for improvements and is in active development.

And this isn't the end. It's just the beginning of a journey towards creating more advanced, more efficient, and more accessible diffusion models. We invite you to join us on this exciting journey. üöÄ

---

<h2>Getting Started with the Demo üíª</h2>

Ready to dive in? Here's how you can get started with the demo.

<h3>1Ô∏è‚É£ : Clone our GitHub repository</h3>

First things first, you'll need to clone our repository. Open up your terminal, navigate to the directory where you want the repository to be cloned, and run the following command:

```
git clone github.com/BudEcosystem/Chhavi.git
```

<h3>2Ô∏è‚É£ : Install dependencies</h3>

Navigate into the cloned repository and install the necessary dependencies with the following command:

```
pip install -r requirements.txt
```

<h3>3Ô∏è‚É£ : Run Demo App</h3>

The gradio interface is provided by our `app.py` script, to run the interface, run the following command:

```
python app.py
```

‚úÖ The interface will run at port `7861` by default and can be accessed either via the local url `http://0.0.0.0:7861/` or the public url generated by gradio (this is auto generated and the namespace changes with restart).

---

<h2>Getting Started on Hugging Face ü§ó</h2>

Getting up and running with our models on Hugging Face is a breeze. Follow these steps:

<h3>1Ô∏è‚É£ : Install dependencies</h3>

Make sure to upgrade diffusers to >= 0.19.0:
```
pip install diffusers --upgrade
```

In addition make sure to install `transformers`, `safetensors`, `accelerate` as well as the invisible watermark:
```
pip install invisible_watermark transformers accelerate safetensors
```

<h3> 2Ô∏è‚É£ : Import necessary modules</h3>

Start by importing the necessary modules from the 'diffusers' library and 'torch'.

```py
from diffusers import DiffusionPipeline
import torch

pipe = DiffusionPipeline.from_pretrained("budecosystem/Chhavi", torch_dtype=torch.float16, use_safetensors=True)
pipe.to("cuda")

# if using torch < 2.0
# pipe.enable_xformers_memory_efficient_attention()

prompt = "Vector anime chibi style logo featuring a single piece of flaming piece of popcorn with a smiling face, with mirrorshades sunglasses, popcorn as morpheus, clean composition, symmetrical"

negative_prompt = "tiling, out of frame, watermark, signature, cut off, low contrast, underexposed, overexposed, bad art, beginner, amateur"

images = pipe(prompt=prompt, negative_prompt=negative_prompt).images[0]
```

When using `torch >= 2.0`, you can improve the inference speed by 20-30% with torch.compile. Simple wrap the unet with torch compile before running the pipeline:
```py
pipe.unet = torch.compile(pipe.unet, mode="reduce-overhead", fullgraph=True)
```

If you are limited by GPU VRAM, you can enable *cpu offloading* by calling `pipe.enable_model_cpu_offload`
instead of `.to("cuda")`:

```diff
- pipe.to("cuda")
+ pipe.enable_model_cpu_offload()
```

<h3> 3Ô∏è‚É£ : Prompt Guidelines</h3>


Chhavi doesn't follow any specific prompt style or template but we've observed the use of the keyword "logo" in the prompt yield better results. It's worth noting that the use of negative prompt will help in reducing any unwanted artifacts in the generation, the negative prompt mentioned in the above code snippet should serve as a good kick-start.

---

<h2>Model Card for Chhavi üìÑ</h2>

Here's a quick overview of everything you need to know about Chhavi.

<h3>Model Details:</h3>


- **Developed by**: Bud Ecosystem
- **Base pretrained model type**: SDXL Base 1.0
- **Model Description:** This is a model that can be used to generate and modify images (specifically finetuned for logos) based on text prompts. It is a [Latent Diffusion Model](https://arxiv.org/abs/2112.10752) that uses two fixed, pretrained text encoders ([OpenCLIP-ViT/G](https://github.com/mlfoundations/open_clip) and [CLIP-ViT/L](https://github.com/openai/CLIP/tree/main)).
- **License**: [CreativeML Open RAIL++-M License](https://huggingface.co/budecosystem/Chhavi/blob/main/LICENSE.md)

---

<h2>Intended Use üíº</h2>

When we created Chhavi, we had a clear vision of how it could be used to push the boundaries of what's possible with diffusion models. We also understand the importance of using such models responsibly. Here's a brief overview of the intended and out-of-scope uses for Chhavi.

<h3>Direct Use</h3>

Chhavi is designed to generate logo images, which can be utilized for the following: 

- Generation of artworks and use in design and other artistic processes.
- Applications in educational or creative tools.


Excluded uses are described below.

<h3>Out-of-Scope Use üö©</h3>

The model was not trained to be factual or true representations of people or events, and therefore using the model to generate such content is out-of-scope for the abilities of this model.

<h3>Recommendations üß†</h3>

We recommend users of Chhavi to take appropriate precautions and guardrails for any production use. Using Chhavi responsibly is key to unlocking its full potential while maintaining a safe and respectful environment.

---

<h2>Looking Ahead üëÄ</h2>

We're excited about the journey ahead with Chhavi. We're committed to continuously improving and enhancing our models, and we're excited to see what the open-source community will build with them. We believe in the power of collaboration, and we can't wait to see what we can achieve together.

Remember, we're just getting started. This is just the beginning of a journey that we believe will revolutionize the world of Generative AI models. We invite you to join us on this exciting journey. Together, we can push the boundaries of what's possible with AI. üöÄ

---
